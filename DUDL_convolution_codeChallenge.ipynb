{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DUDL_convolution_codeChallenge.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mb0fBtyfEpsj"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamednasr/deep-learning/blob/main/DUDL_convolution_codeChallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhWV8oes-wKR"
      },
      "source": [
        "# COURSE: A deep understanding of deep learning\n",
        "## SECTION: Convolution and transformations\n",
        "### LECTURE: CodeChallenge: choose the parameters\n",
        "#### TEACHER: Mike X Cohen, sincxpress.com\n",
        "##### COURSE URL: udemy.com/course/dudl/?couponCode=202109"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeuAheYyhdZw"
      },
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HOkOefftqyg"
      },
      "source": [
        "# Sample problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiLI77Lh9yms"
      },
      "source": [
        "### Convolve an image of size 1x256x256 to produce a 1x252x84 result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhIKo0_iaGz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "517ad21c-29c4-455a-99ae-c2793e67bbb5"
      },
      "source": [
        "# parameters\n",
        "inChans  = 1 # RGB\n",
        "imsize   = [256,256]\n",
        "outChans = 1\n",
        "krnSize  = 7 # should be an odd number\n",
        "stride   = (1,3)\n",
        "padding  = 1\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans,0,0],dtype=int)\n",
        "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
        "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [  1 252  84]\n",
            "Empirical size: [252, 84]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCWyuNySDagy"
      },
      "source": [
        "# Real problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bteB_P10DSCM"
      },
      "source": [
        "### 1) Convolve an image of size 3x64x64 to produce a 10x28x28 result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8CM5aVADSCN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc5696e2-b3a0-4d4d-bd3a-a7b174db6734"
      },
      "source": [
        "# parameters\n",
        "inChans  = 3\n",
        "imsize   = [64,64]\n",
        "outChans = 10\n",
        "krnSize  = 9\n",
        "stride   = (2,2)\n",
        "padding  = 0\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans,0,0],dtype=int)\n",
        "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
        "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [10 28 28]\n",
            "Empirical size: [10, 28, 28]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jfWAkiWDWU7"
      },
      "source": [
        "### 2) Convolve an image of size 3x196x96 to produce a 5x66x49 result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XieXWJ9gDWU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72826b0f-00e2-4af9-b33d-dd8f8e882642"
      },
      "source": [
        "# parameters\n",
        "inChans  = 3\n",
        "imsize   = [196,96]\n",
        "outChans = 5\n",
        "krnSize  = 5\n",
        "stride   = (3,2)\n",
        "padding  = 3\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans,0,0],dtype=int)\n",
        "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
        "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [ 5 66 49]\n",
            "Empirical size: [5, 66, 49]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdRhRVE7FfN2"
      },
      "source": [
        "### 3) Convolve an image of size 1x32x32 to produce a 6x28x28 result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5f9x7HjFfN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d139114e-4d1e-4c69-a995-abed4c35bcae"
      },
      "source": [
        "# note: these dimensions are the input -> first hidden layer of the famous LeNet-5\n",
        "\n",
        "# parameters\n",
        "inChans  = 1\n",
        "imsize   = [32,32]\n",
        "outChans = 6\n",
        "krnSize  = 5\n",
        "stride   = (1,1)\n",
        "padding  = 0\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans,0,0],dtype=int)\n",
        "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
        "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [ 6 28 28]\n",
            "Empirical size: [6, 28, 28]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrHM60CkF2pl"
      },
      "source": [
        "### 4) Convolve an image of size 3x227x227 to produce a 96x55x55 result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0R0DITNF2pl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe79240e-790f-43cd-ea24-a50c83beffcd"
      },
      "source": [
        "# note: these dimensions are the input -> first hidden layer of the famous AlexNet\n",
        "\n",
        "# parameters\n",
        "inChans  = 3\n",
        "imsize   = [227,227]\n",
        "outChans = 96\n",
        "krnSize  = 11\n",
        "stride   = (4,4)\n",
        "padding  = 0\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans,0,0],dtype=int)\n",
        "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
        "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [96 55 55]\n",
            "Empirical size: [96, 55, 55]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvoJ9X5IHtl5"
      },
      "source": [
        "### 5) Convolve an image of size 3x224x224 to produce a 64x224x224 result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG4InNjQHtl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c8d6b05-668d-45e6-b108-0c6e02528d64"
      },
      "source": [
        "# note: these dimensions are the input -> first hidden layer of the famous VGG-16\n",
        "\n",
        "# parameters\n",
        "inChans  = 3\n",
        "imsize   = [224,224]\n",
        "outChans = 64\n",
        "krnSize  = 5\n",
        "stride   = (1,1)\n",
        "padding  = 2\n",
        "\n",
        "# create the instance\n",
        "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
        "\n",
        "# create an image\n",
        "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
        "\n",
        "# run convolution and compute its shape\n",
        "resimg = c(img)\n",
        "empSize = torch.squeeze(resimg).shape\n",
        "\n",
        "# compute the size of the result according to the formula\n",
        "expectSize = np.array([outChans,0,0],dtype=int)\n",
        "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
        "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
        "\n",
        "# check the size of the output\n",
        "print(f'Expected size: {expectSize}')\n",
        "print(f'Empirical size: {list(empSize)}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected size: [ 64 224 224]\n",
            "Empirical size: [64, 224, 224]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8zLORJxEpqY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-P_8vOjIVeP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDmDF1pPIVgn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXW4RaOAIVi4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLsIIb--IVkv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzMISeuyIVmx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTTygSkjIVov"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbnr43FxIVq_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn6a-vl4IVs6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb0fBtyfEpsj"
      },
      "source": [
        "# Answers (don't cheat!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwR_5NyFErcf"
      },
      "source": [
        "# 1)\n",
        "inChans  = 3\n",
        "imsize   = [64,64]\n",
        "outChans = 10\n",
        "krnSize  = 9\n",
        "stride   = (2,2)\n",
        "padding  = 0\n",
        "\n",
        "# 2)\n",
        "inChans  = 3\n",
        "imsize   = [196,96]\n",
        "outChans = 5\n",
        "krnSize  = 5\n",
        "stride   = (3,2)\n",
        "padding  = 3\n",
        "\n",
        "# 3)\n",
        "inChans  = 1\n",
        "imsize   = [32,32]\n",
        "outChans = 6\n",
        "krnSize  = 5\n",
        "stride   = (1,1)\n",
        "padding  = 0\n",
        "\n",
        "# 4)\n",
        "inChans  = 3\n",
        "imsize   = [227,227]\n",
        "outChans = 96\n",
        "krnSize  = 11\n",
        "stride   = (4,4)\n",
        "padding  = 1\n",
        "\n",
        "# 5)\n",
        "inChans  = 3\n",
        "imsize   = [224,224]\n",
        "outChans = 64\n",
        "krnSize  = 3\n",
        "stride   = (1,1)\n",
        "padding  = 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}